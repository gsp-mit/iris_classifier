{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris=load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DESCR',\n",
       " 'data',\n",
       " 'feature_names',\n",
       " 'filename',\n",
       " 'frame',\n",
       " 'target',\n",
       " 'target_names']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2],\n",
       "       [5.4, 3.9, 1.7, 0.4],\n",
       "       [4.6, 3.4, 1.4, 0.3],\n",
       "       [5. , 3.4, 1.5, 0.2],\n",
       "       [4.4, 2.9, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [5.4, 3.7, 1.5, 0.2],\n",
       "       [4.8, 3.4, 1.6, 0.2],\n",
       "       [4.8, 3. , 1.4, 0.1],\n",
       "       [4.3, 3. , 1.1, 0.1],\n",
       "       [5.8, 4. , 1.2, 0.2],\n",
       "       [5.7, 4.4, 1.5, 0.4],\n",
       "       [5.4, 3.9, 1.3, 0.4],\n",
       "       [5.1, 3.5, 1.4, 0.3],\n",
       "       [5.7, 3.8, 1.7, 0.3],\n",
       "       [5.1, 3.8, 1.5, 0.3],\n",
       "       [5.4, 3.4, 1.7, 0.2],\n",
       "       [5.1, 3.7, 1.5, 0.4],\n",
       "       [4.6, 3.6, 1. , 0.2],\n",
       "       [5.1, 3.3, 1.7, 0.5],\n",
       "       [4.8, 3.4, 1.9, 0.2],\n",
       "       [5. , 3. , 1.6, 0.2],\n",
       "       [5. , 3.4, 1.6, 0.4],\n",
       "       [5.2, 3.5, 1.5, 0.2],\n",
       "       [5.2, 3.4, 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.6, 0.2],\n",
       "       [4.8, 3.1, 1.6, 0.2],\n",
       "       [5.4, 3.4, 1.5, 0.4],\n",
       "       [5.2, 4.1, 1.5, 0.1],\n",
       "       [5.5, 4.2, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.2, 1.2, 0.2],\n",
       "       [5.5, 3.5, 1.3, 0.2],\n",
       "       [4.9, 3.6, 1.4, 0.1],\n",
       "       [4.4, 3. , 1.3, 0.2],\n",
       "       [5.1, 3.4, 1.5, 0.2],\n",
       "       [5. , 3.5, 1.3, 0.3],\n",
       "       [4.5, 2.3, 1.3, 0.3],\n",
       "       [4.4, 3.2, 1.3, 0.2],\n",
       "       [5. , 3.5, 1.6, 0.6],\n",
       "       [5.1, 3.8, 1.9, 0.4],\n",
       "       [4.8, 3. , 1.4, 0.3],\n",
       "       [5.1, 3.8, 1.6, 0.2],\n",
       "       [4.6, 3.2, 1.4, 0.2],\n",
       "       [5.3, 3.7, 1.5, 0.2],\n",
       "       [5. , 3.3, 1.4, 0.2],\n",
       "       [7. , 3.2, 4.7, 1.4],\n",
       "       [6.4, 3.2, 4.5, 1.5],\n",
       "       [6.9, 3.1, 4.9, 1.5],\n",
       "       [5.5, 2.3, 4. , 1.3],\n",
       "       [6.5, 2.8, 4.6, 1.5],\n",
       "       [5.7, 2.8, 4.5, 1.3],\n",
       "       [6.3, 3.3, 4.7, 1.6],\n",
       "       [4.9, 2.4, 3.3, 1. ],\n",
       "       [6.6, 2.9, 4.6, 1.3],\n",
       "       [5.2, 2.7, 3.9, 1.4],\n",
       "       [5. , 2. , 3.5, 1. ],\n",
       "       [5.9, 3. , 4.2, 1.5],\n",
       "       [6. , 2.2, 4. , 1. ],\n",
       "       [6.1, 2.9, 4.7, 1.4],\n",
       "       [5.6, 2.9, 3.6, 1.3],\n",
       "       [6.7, 3.1, 4.4, 1.4],\n",
       "       [5.6, 3. , 4.5, 1.5],\n",
       "       [5.8, 2.7, 4.1, 1. ],\n",
       "       [6.2, 2.2, 4.5, 1.5],\n",
       "       [5.6, 2.5, 3.9, 1.1],\n",
       "       [5.9, 3.2, 4.8, 1.8],\n",
       "       [6.1, 2.8, 4. , 1.3],\n",
       "       [6.3, 2.5, 4.9, 1.5],\n",
       "       [6.1, 2.8, 4.7, 1.2],\n",
       "       [6.4, 2.9, 4.3, 1.3],\n",
       "       [6.6, 3. , 4.4, 1.4],\n",
       "       [6.8, 2.8, 4.8, 1.4],\n",
       "       [6.7, 3. , 5. , 1.7],\n",
       "       [6. , 2.9, 4.5, 1.5],\n",
       "       [5.7, 2.6, 3.5, 1. ],\n",
       "       [5.5, 2.4, 3.8, 1.1],\n",
       "       [5.5, 2.4, 3.7, 1. ],\n",
       "       [5.8, 2.7, 3.9, 1.2],\n",
       "       [6. , 2.7, 5.1, 1.6],\n",
       "       [5.4, 3. , 4.5, 1.5],\n",
       "       [6. , 3.4, 4.5, 1.6],\n",
       "       [6.7, 3.1, 4.7, 1.5],\n",
       "       [6.3, 2.3, 4.4, 1.3],\n",
       "       [5.6, 3. , 4.1, 1.3],\n",
       "       [5.5, 2.5, 4. , 1.3],\n",
       "       [5.5, 2.6, 4.4, 1.2],\n",
       "       [6.1, 3. , 4.6, 1.4],\n",
       "       [5.8, 2.6, 4. , 1.2],\n",
       "       [5. , 2.3, 3.3, 1. ],\n",
       "       [5.6, 2.7, 4.2, 1.3],\n",
       "       [5.7, 3. , 4.2, 1.2],\n",
       "       [5.7, 2.9, 4.2, 1.3],\n",
       "       [6.2, 2.9, 4.3, 1.3],\n",
       "       [5.1, 2.5, 3. , 1.1],\n",
       "       [5.7, 2.8, 4.1, 1.3],\n",
       "       [6.3, 3.3, 6. , 2.5],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [7.1, 3. , 5.9, 2.1],\n",
       "       [6.3, 2.9, 5.6, 1.8],\n",
       "       [6.5, 3. , 5.8, 2.2],\n",
       "       [7.6, 3. , 6.6, 2.1],\n",
       "       [4.9, 2.5, 4.5, 1.7],\n",
       "       [7.3, 2.9, 6.3, 1.8],\n",
       "       [6.7, 2.5, 5.8, 1.8],\n",
       "       [7.2, 3.6, 6.1, 2.5],\n",
       "       [6.5, 3.2, 5.1, 2. ],\n",
       "       [6.4, 2.7, 5.3, 1.9],\n",
       "       [6.8, 3. , 5.5, 2.1],\n",
       "       [5.7, 2.5, 5. , 2. ],\n",
       "       [5.8, 2.8, 5.1, 2.4],\n",
       "       [6.4, 3.2, 5.3, 2.3],\n",
       "       [6.5, 3. , 5.5, 1.8],\n",
       "       [7.7, 3.8, 6.7, 2.2],\n",
       "       [7.7, 2.6, 6.9, 2.3],\n",
       "       [6. , 2.2, 5. , 1.5],\n",
       "       [6.9, 3.2, 5.7, 2.3],\n",
       "       [5.6, 2.8, 4.9, 2. ],\n",
       "       [7.7, 2.8, 6.7, 2. ],\n",
       "       [6.3, 2.7, 4.9, 1.8],\n",
       "       [6.7, 3.3, 5.7, 2.1],\n",
       "       [7.2, 3.2, 6. , 1.8],\n",
       "       [6.2, 2.8, 4.8, 1.8],\n",
       "       [6.1, 3. , 4.9, 1.8],\n",
       "       [6.4, 2.8, 5.6, 2.1],\n",
       "       [7.2, 3. , 5.8, 1.6],\n",
       "       [7.4, 2.8, 6.1, 1.9],\n",
       "       [7.9, 3.8, 6.4, 2. ],\n",
       "       [6.4, 2.8, 5.6, 2.2],\n",
       "       [6.3, 2.8, 5.1, 1.5],\n",
       "       [6.1, 2.6, 5.6, 1.4],\n",
       "       [7.7, 3. , 6.1, 2.3],\n",
       "       [6.3, 3.4, 5.6, 2.4],\n",
       "       [6.4, 3.1, 5.5, 1.8],\n",
       "       [6. , 3. , 4.8, 1.8],\n",
       "       [6.9, 3.1, 5.4, 2.1],\n",
       "       [6.7, 3.1, 5.6, 2.4],\n",
       "       [6.9, 3.1, 5.1, 2.3],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [6.8, 3.2, 5.9, 2.3],\n",
       "       [6.7, 3.3, 5.7, 2.5],\n",
       "       [6.7, 3. , 5.2, 2.3],\n",
       "       [6.3, 2.5, 5. , 1.9],\n",
       "       [6.5, 3. , 5.2, 2. ],\n",
       "       [6.2, 3.4, 5.4, 2.3],\n",
       "       [5.9, 3. , 5.1, 1.8]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
       "0                5.1               3.5                1.4               0.2\n",
       "1                4.9               3.0                1.4               0.2\n",
       "2                4.7               3.2                1.3               0.2\n",
       "3                4.6               3.1                1.5               0.2\n",
       "4                5.0               3.6                1.4               0.2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame(iris.data,columns=iris.feature_names)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                  5.1               3.5                1.4               0.2   \n",
       "1                  4.9               3.0                1.4               0.2   \n",
       "2                  4.7               3.2                1.3               0.2   \n",
       "3                  4.6               3.1                1.5               0.2   \n",
       "4                  5.0               3.6                1.4               0.2   \n",
       "..                 ...               ...                ...               ...   \n",
       "145                6.7               3.0                5.2               2.3   \n",
       "146                6.3               2.5                5.0               1.9   \n",
       "147                6.5               3.0                5.2               2.0   \n",
       "148                6.2               3.4                5.4               2.3   \n",
       "149                5.9               3.0                5.1               1.8   \n",
       "\n",
       "     target  \n",
       "0         0  \n",
       "1         0  \n",
       "2         0  \n",
       "3         0  \n",
       "4         0  \n",
       "..      ...  \n",
       "145       2  \n",
       "146       2  \n",
       "147       2  \n",
       "148       2  \n",
       "149       2  \n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['target']=iris.target\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.hist([df['sepal length (cm)'],df['sepal width (cm)']],label=['sepal_length','sepal_width'],color=['green','blue'])\n",
    "plt.xlabel('Targets')\n",
    "plt.ylabel('Sepal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "sns.histplot(data=[df['sepal length (cm)'],df['sepal width (cm)']])\n",
    "plt.xlabel('Targets')\n",
    "plt.ylabel('Sepal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.843333</td>\n",
       "      <td>3.057333</td>\n",
       "      <td>3.758000</td>\n",
       "      <td>1.199333</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.828066</td>\n",
       "      <td>0.435866</td>\n",
       "      <td>1.765298</td>\n",
       "      <td>0.762238</td>\n",
       "      <td>0.819232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.300000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.100000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.800000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.350000</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.400000</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.900000</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>6.900000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sepal length (cm)  sepal width (cm)  petal length (cm)  \\\n",
       "count         150.000000        150.000000         150.000000   \n",
       "mean            5.843333          3.057333           3.758000   \n",
       "std             0.828066          0.435866           1.765298   \n",
       "min             4.300000          2.000000           1.000000   \n",
       "25%             5.100000          2.800000           1.600000   \n",
       "50%             5.800000          3.000000           4.350000   \n",
       "75%             6.400000          3.300000           5.100000   \n",
       "max             7.900000          4.400000           6.900000   \n",
       "\n",
       "       petal width (cm)      target  \n",
       "count        150.000000  150.000000  \n",
       "mean           1.199333    1.000000  \n",
       "std            0.762238    0.819232  \n",
       "min            0.100000    0.000000  \n",
       "25%            0.300000    0.000000  \n",
       "50%            1.300000    1.000000  \n",
       "75%            1.800000    2.000000  \n",
       "max            2.500000    2.000000  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 5 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   sepal length (cm)  150 non-null    float64\n",
      " 1   sepal width (cm)   150 non-null    float64\n",
      " 2   petal length (cm)  150 non-null    float64\n",
      " 3   petal width (cm)   150 non-null    float64\n",
      " 4   target             150 non-null    int32  \n",
      "dtypes: float64(4), int32(1)\n",
      "memory usage: 5.4 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop('target',axis='columns')\n",
    "y=df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(X,y,test_size=0.1,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores=[]\n",
    "model_params={\n",
    "    \n",
    "    'SVM':{\n",
    "        'model':svm.SVC(gamma='auto'),\n",
    "        'params':{\n",
    "            'C':[1,10,20],\n",
    "            'kernel':['linear', 'poly', 'rbf', 'sigmoid']\n",
    "        }\n",
    "    },\n",
    "    \n",
    "    'random_forest': {\n",
    "        'model':RandomForestClassifier(),\n",
    "        'params':{\n",
    "            'n_estimators':[1,5,10,100],\n",
    "            'criterion':['gini','entropy'],\n",
    "            'max_depth':[None,10,20,100],\n",
    "            'max_features':[\"auto\", \"sqrt\", \"log2\"]\n",
    "        }\n",
    "    },\n",
    "    \n",
    "    'LogisticRegression':{\n",
    "        'model':LogisticRegression(multi_class='auto'),\n",
    "       'params':{\n",
    "           'C':[1,5,10],\n",
    "           'penalty':['l1', 'l2', 'elasticnet', 'none'],\n",
    "           'solver':['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
    "       }\n",
    "    },\n",
    "    \n",
    "    'DecisionTreeClassifier':{\n",
    "        'model':DecisionTreeClassifier(),\n",
    "        'params':{\n",
    "            'criterion':['gini','entropy'],\n",
    "            'splitter':[\"best\", \"random\"],\n",
    "            'max_depth':[None,1,10,20]\n",
    "        }\n",
    "    }\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 449, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1312, in fit\n",
      "    raise ValueError(\"l1_ratio must be between 0 and 1;\"\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 453, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 449, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1312, in fit\n",
      "    raise ValueError(\"l1_ratio must be between 0 and 1;\"\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 453, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 449, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1312, in fit\n",
      "    raise ValueError(\"l1_ratio must be between 0 and 1;\"\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 453, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>best_score</th>\n",
       "      <th>best_params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>{'C': 1, 'kernel': 'linear'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': None, 'max_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.986667</td>\n",
       "      <td>{'C': 1, 'penalty': 'l1', 'solver': 'saga'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': None, 'spli...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    model  best_score  \\\n",
       "0                     SVM    0.980000   \n",
       "1           random_forest    0.966667   \n",
       "2      LogisticRegression    0.986667   \n",
       "3  DecisionTreeClassifier    0.966667   \n",
       "\n",
       "                                         best_params  \n",
       "0                       {'C': 1, 'kernel': 'linear'}  \n",
       "1  {'criterion': 'gini', 'max_depth': None, 'max_...  \n",
       "2        {'C': 1, 'penalty': 'l1', 'solver': 'saga'}  \n",
       "3  {'criterion': 'gini', 'max_depth': None, 'spli...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for model_name, mp in model_params.items():\n",
    "    clf=GridSearchCV(mp['model'],mp['params'],cv=5,return_train_score=False)\n",
    "    clf.fit(X,y)\n",
    "    scores.append({\n",
    "        'model':model_name,\n",
    "        'best_score':clf.best_score_,\n",
    "        'best_params': clf.best_params_\n",
    "    })\n",
    "\n",
    "new_df=pd.DataFrame(scores,columns=['model','best_score','best_params'])\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scores=[]\n",
    "\n",
    "# for model_name,mp in model_params.items():\n",
    "#     clf=GridSearchCV(mp['model'],mp['params'],cv=5,return_train_score=False)\n",
    "#     clf.fit(x,y)\n",
    "#     scores.append({\n",
    "#         'Model':model_name,\n",
    "#         'best_score':clf.best_score_,\n",
    "#         'best_params':clf.best_params_\n",
    "#     })\n",
    "    \n",
    "# df=pd.DataFrame(scores, columns=['model','best_score','best_params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=svm.SVC(gamma='auto',C=1,kernel='rbf')\n",
    "model.fit(X,y)\n",
    "model.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 2, 1, 1, 0, 1, 2, 1, 1, 2, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions=model.predict(x_test)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_pred=predictions.mean()\n",
    "mean_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, penalty='l1', solver='saga')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2=LogisticRegression(C=1,penalty='l1',solver='saga',multi_class='auto')\n",
    "model_2.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6, 0, 0],\n",
       "       [0, 6, 0],\n",
       "       [0, 0, 3]], dtype=int64)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm=confusion_matrix(y_test,predictions)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "sns.heatmap(cm,annot=True)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
